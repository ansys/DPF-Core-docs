{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Average Stress in distributed Workflows\nThis example shows how stress can be read from distributed files and\naveraged from elemental nodal to nodal in parallel with a distributed workflow.\nAfter remote post-processing, results are merged on the local process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import dpf module and its examples files\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ansys.dpf import core as dpf\nfrom ansys.dpf.core import examples\nfrom ansys.dpf.core import operators as ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configure the servers\nMake a list of ip addresses and port numbers on which dpf servers are\nstarted. Workflow instances will be created on each of these servers to\naddress each a different result file.\nIn this example, we will post process an analysis distributed in 2 files,\nwe will consequently require 2 remote processes.\nTo make this example easier, we will start local servers here,\nbut we could get connected to any existing servers on the network.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "files = examples.download_distributed_files()\n\nconfig = dpf.ServerConfig(protocol=dpf.server.CommunicationProtocols.gRPC)\nremote_servers = [dpf.start_local_server(as_global=False, config=config) for file in files]\nips = [remote_server.ip for remote_server in remote_servers]\nports = [remote_server.port for remote_server in remote_servers]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the ips and ports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"ips:\", ips)\nprint(\"ports:\", ports)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distributed Workflow\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. graphviz::\n\n   digraph foo {\n       graph [pad=\"0\", nodesep=\"0.3\", ranksep=\"0.3\"]\n       node [shape=box, style=filled, fillcolor=\"#ffcc00\", margin=\"0\"];\n       rankdir=LR;\n       splines=line;\n\n       stress01 [label=\"stress\"];\n       stress02 [label=\"stress\"];\n       average01 [label=\"elemental_nodal_to_nodal_fc\"];\n       average02 [label=\"elemental_nodal_to_nodal_fc\"];\n\n       subgraph cluster_1 {\n           ds01 [label=\"data_src\", shape=box, style=filled, fillcolor=cadetblue2];\n           no_extend_to_mid_nodes01 [label=\"no_extend_to_mid_nodes\",\n                                     shape=box, style=filled, fillcolor=cadetblue2];\n\n           ds01 -> stress01 [style=dashed];\n           no_extend_to_mid_nodes01 -> stress01 [style=dashed];\n           stress01 -> average01;\n\n           label=\"Server 2\";\n           style=filled;\n           fillcolor=lightgrey;\n       }\n\n       subgraph cluster_2 {\n           ds02 [label=\"data_src\", shape=box, style=filled, fillcolor=cadetblue2];\n           no_extend_to_mid_nodes02 [label=\"no_extend_to_mid_nodes\",\n                                     shape=box, style=filled, fillcolor=cadetblue2];\n\n           ds02 -> stress02 [style=dashed];\n           no_extend_to_mid_nodes02 -> stress02 [style=dashed];\n           stress02 -> average02;\n\n           label=\"Server 1\";\n           style=filled;\n           fillcolor=lightgrey;\n       }\n       merge_weighted_fields_containers [label=\"merge_weighted_fields_containers\"];\n       average01 -> merge_weighted_fields_containers;\n       average02 -> merge_weighted_fields_containers;\n       merge_weighted_fields_containers -> extend_to_mid_nodes;\n\n   }\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a local workflow able to merge the results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "config = ops.utility.merge_weighted_fields_containers.default_config()\nconfig.set_read_inputs_in_parallel_option(True)\nmerge = ops.utility.merge_weighted_fields_containers(config=config)\nextend_to_mid_nodes = ops.averaging.extend_to_mid_nodes_fc(merge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Send workflows on servers\nHere we create new instances on the server by copies of the template workflow\nWe also connect the data sources to those workflows\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "remote_workflows = []\nfor i, server in enumerate(remote_servers):\n    ds = dpf.DataSources(files[i], server=server)\n    stress = ops.result.stress(server=server)\n    stress.inputs.connect(ds)\n    average = ops.averaging.elemental_nodal_to_nodal_fc(stress)\n    average.inputs.extend_to_mid_nodes(False)\n\n    merge.connect(0 + i, average.outputs.fields_container)\n    merge.connect(1000 + i, average, 1)\n\nfc = extend_to_mid_nodes.outputs.fields_container()\nfc[0].plot()\nprint(fc)\nprint(fc[0].min().data)\nprint(fc[0].max().data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compare with non distributed Workflow\nCreate DataSources with Domain id (one domain by distributed file).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds = dpf.DataSources()\nds.set_domain_result_file_path(files[0], 0)\nds.set_domain_result_file_path(files[1], 1)\n\nmodel = dpf.Model(ds)\nstress = model.results.stress()\nfc_single_process = ops.averaging.to_nodal_fc(stress).eval()\n\nfc_single_process[0].plot()\nprint(fc_single_process[0].min().data)\nprint(fc_single_process[0].max().data)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}