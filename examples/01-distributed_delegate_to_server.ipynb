{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Compute total displacement from distributed files with distributed post\n",
    "This example shows how distributed files can be read and post processed\n",
    "on distributed processes. After remote post processing of total displacement,\n",
    "results a merged on the local process. In this example, the client is only\n",
    "connected to the coordinator server. Connections to remote processes are only\n",
    "done implicitly through the coordinator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dpf module and its examples files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from ansys.dpf import core as dpf\n",
    "from ansys.dpf.core import examples\n",
    "from ansys.dpf.core import operators as ops\n",
    "from ansys.jupyterhub.manager import spawn_dpf, delete_pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the template workflow of total displacement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "server1, pod1_name = spawn_dpf()\n",
    "template_workflow = dpf.Workflow(server=server1)\n",
    "displacement = ops.result.displacement()\n",
    "norm = ops.math.norm_fc(displacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the operators to the template workflow and name its inputs and outputs\n",
    "Once workflow's inputs and outputs are named, they can be connected later on\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "template_workflow.add_operators([displacement, norm])\n",
    "template_workflow.set_input_name(\"data_sources\", displacement.inputs.data_sources)\n",
    "template_workflow.set_output_name(\"out\", norm.outputs.fields_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the servers\n",
    "Start two more dpf servers. Workflows instances will be created on each of those servers to\n",
    "address each a different result file.\n",
    "In this example, we will post process an analysis distributed in 2 files,\n",
    "we will consequently require 2 remote processes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "server2, pod2_name = spawn_dpf()\n",
    "server3, pod3_name = spawn_dpf()\n",
    "servers = [server2, server3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how we could send files in temporary directory if we were not\n",
    "in shared memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "local_files = examples.download_distributed_files()\n",
    "server_file_paths = [dpf.upload_file_in_tmp_folder(local_files[0], server=server2),\n",
    "                     dpf.upload_file_in_tmp_folder(local_files[1], server=server3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send workflows on servers\n",
    "Here we create new instances on the server by copies of the template workflow\n",
    "We also connect the data sources to those workflows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "remote_workflows = []\n",
    "for i, server in enumerate(servers):\n",
    "    remote_workflows.append(template_workflow.create_on_other_server(server=server))\n",
    "    ds = dpf.DataSources(server_file_paths[i])\n",
    "    remote_workflows[i].connect(\"data_sources\", ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a workflow able to merge the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "workflow = dpf.Workflow()\n",
    "merge = ops.utility.merge_fields_containers()\n",
    "workflow.add_operator(merge)\n",
    "workflow.set_input_name(\"in0\", merge, 0)\n",
    "workflow.set_input_name(\"in1\", merge, 1)\n",
    "workflow.set_output_name(\"merged\", merge.outputs.merged_fields_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect the workflows together and get the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i, server in enumerate(servers):\n",
    "    workflow.connect_with(remote_workflows[i], (\"out\", \"in\" + str(i)))\n",
    "\n",
    "fc = workflow.get_output(\"merged\", dpf.types.fields_container)\n",
    "print(fc)\n",
    "print(fc[0].min().data)\n",
    "print(fc[0].max().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_pod(pod1_name)\n",
    "delete_pod(pod2_name)\n",
    "delete_pod(pod3_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
