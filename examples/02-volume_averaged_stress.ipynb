{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Average Elemental Stress on a given volume\n",
    "This example shows how to find the minimum list of surrounding\n",
    "elements for a given node to get a minimum volume.\n",
    "For each list of elements, the elemental stress eqv are multiplied by the\n",
    "volume of each element. This result is then accumulated to divide it by the\n",
    "total volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from ansys.dpf import core as dpf\n",
    "from ansys.dpf.core import examples\n",
    "from ansys.dpf.core import operators as ops\n",
    "from ansys.jupyterhub.manager import spawn_dpf, delete_pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model targeting a given result file.\n",
    "The model will give an easy access to the mesh, time_freq_support ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "server, pod_name = spawn_dpf()\n",
    "server_file_path = dpf.upload_file_in_tmp_folder(examples.complex_rst, server=server)\n",
    "model = dpf.Model(server_file_path)\n",
    "mesh = model.metadata.meshed_region\n",
    "\n",
    "# Volume size to check\n",
    "volume_check = 4.0e-11\n",
    "\n",
    "# get the all the node ids in the model to find the minimum amount of\n",
    "# surrounding elements to get a minimum volume\n",
    "nodes = mesh.nodes.scoping\n",
    "nodes_ids = nodes.ids\n",
    "nodes_ids_to_compute = []\n",
    "for i in range(0, 400):\n",
    "    nodes_ids_to_compute.append(nodes_ids[i])\n",
    "elements = mesh.elements.scoping\n",
    "elements_ids = elements.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the volume by element\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vol_op = ops.result.elemental_volume()\n",
    "vol_op.inputs.streams_container(model.metadata.streams_provider)\n",
    "vol_field = vol_op.outputs.fields_container()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the minimum list of elements by node to get the volume check\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get the connectivy and inverse connecitivity fields\n",
    "connectivity_field = mesh.elements.connectivities_field\n",
    "nodal_connectivity_field = mesh.nodes.nodal_connectivity_field\n",
    "\n",
    "node_index_to_el_ids = {}\n",
    "node_index_to_found_volume = {}\n",
    "# using the with statement with as_local_field allows to bring the server's\n",
    "# data locally and to work only on the local process before sending the data\n",
    "# updates to the server as the end of the with statement\n",
    "# the performances are a lot better using this syntax\n",
    "with connectivity_field.as_local_field() as connectivity:\n",
    "    with nodal_connectivity_field.as_local_field() as nodal_connectivity:\n",
    "        with vol_field.as_local_field() as vol:\n",
    "            for i, node in enumerate(nodes_ids_to_compute):\n",
    "\n",
    "                current_node_indexes = [i]\n",
    "                volume = 0.0\n",
    "                # Loop through recursively selecting elements attached\n",
    "                # to nodes until specified volume is reached\n",
    "                while volume_check > volume:\n",
    "                    volume = 0.0\n",
    "                    elements_indexes = []\n",
    "                    # get elements attached to nodes\n",
    "                    for current_node_index in current_node_indexes:\n",
    "                        elements_indexes.extend(\n",
    "                            nodal_connectivity.get_entity_data(i).flatten()\n",
    "                        )\n",
    "\n",
    "                    current_node_indexes = []\n",
    "                    for index in elements_indexes:\n",
    "                        # sum up the volume on those elements\n",
    "                        volume += vol.get_entity_data(index)[0]\n",
    "\n",
    "                        # get all nodes of the current elements for next iteration\n",
    "                        current_node_indexes.extend(connectivity.get_entity_data(index))\n",
    "                node_index_to_el_ids[i] = dpf.Scoping(\n",
    "                    ids=[elements_ids[index] for index in elements_indexes],\n",
    "                    location=dpf.locations().elemental,\n",
    "                )\n",
    "                node_index_to_found_volume[i] = volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create workflow\n",
    "For each list of elements surrounding nodes:\n",
    "compute stress eqv averaged on elements\n",
    "apply dot product seqv.volume\n",
    "sum up those on the list of elements\n",
    "divide this sum by the total volume on those elements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "s = model.results.stress()\n",
    "to_elemental = ops.averaging.to_elemental_fc(s)\n",
    "eqv = ops.invariant.von_mises_eqv_fc(to_elemental)\n",
    "values_to_sum_field = eqv.outputs.fields_container()[0]\n",
    "\n",
    "# sum up the seqv by list of elements and create a Field\n",
    "seqvsum = dpf.fields_factory.create_scalar_field(len(nodes), dpf.locations.nodal)\n",
    "dataseqvsum = []\n",
    "volsum = dpf.fields_factory.create_scalar_field(len(nodes), dpf.locations.nodal)\n",
    "datavolsum = []\n",
    "\n",
    "with values_to_sum_field.as_local_field() as values_to_sum:\n",
    "    with vol_field.as_local_field() as vol:\n",
    "        for key in node_index_to_el_ids:\n",
    "            ssum = 0.0\n",
    "            for id in node_index_to_el_ids[key]:\n",
    "                ssum += (\n",
    "                        values_to_sum.get_entity_data_by_id(id)[0]\n",
    "                        * vol.get_entity_data_by_id(id)[0]\n",
    "                )\n",
    "            dataseqvsum.append(ssum)\n",
    "            datavolsum.append(node_index_to_found_volume[key])\n",
    "\n",
    "seqvsum.data = dataseqvsum\n",
    "seqvsum.scoping.ids = nodes_ids_to_compute\n",
    "\n",
    "volsum.data = datavolsum\n",
    "volsum.scoping.ids = nodes_ids_to_compute\n",
    "\n",
    "# use component wise divide to averaged the stress by the volume\n",
    "divide = ops.math.component_wise_divide(seqvsum, volsum)\n",
    "divide.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot elemental seqv and volume averaged elemental seqv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mesh.plot(values_to_sum_field)\n",
    "mesh.plot(divide.outputs.field())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the Operator instead\n",
    "An operator with the same algorithm has been implemented\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "s_fc = s.outputs.fields_container()\n",
    "single_field_vol_fc = dpf.fields_container_factory.over_time_freq_fields_container(\n",
    "    [vol_field]\n",
    ")\n",
    "\n",
    "single_field_fc = dpf.fields_container_factory.over_time_freq_fields_container(\n",
    "    [values_to_sum_field]\n",
    ")\n",
    "\n",
    "op = dpf.Operator(\"volume_stress\")\n",
    "op.inputs.scoping.connect(nodes)\n",
    "op.inputs.stress_fields.connect(single_field_fc)\n",
    "op.inputs.volume_fields(single_field_vol_fc)\n",
    "op.inputs.volume(volume_check * 10.0)\n",
    "\n",
    "out = op.get_output(0, dpf.types.field)\n",
    "mesh.plot(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_pod(pod_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
