{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Write user defined Operators as a package\n",
    "This example shows how more complex DPF python plugins of Operators can be created as standard python packages.\n",
    "The benefits of writing packages instead of simple scripts are: componentization (split the code in several\n",
    "python modules or files), distribution (with packages, standard python tools can be used to upload and\n",
    "download packages) and documentation (READMEs, docs, tests and examples can be added to the package).\n",
    "\n",
    "This plugin will hold 2 different Operators:\n",
    "  - One returning all the scoping ids having data higher than the average\n",
    "  - One returning all the scoping ids having data lower than the average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Operator\n",
    "For this more advanced use case, a python package is created.\n",
    "Each Operator implementation derives from `ansys.dpf.core.custom_operator.CustomOperatorBase`\n",
    "and a call to `ansys.dpf.core.custom_operator.record_operator` records the Operators of the plugin.\n",
    "The complete package looks like:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m average_filter_plugin\n",
      "\u001b[1m __init__.py:\n",
      " \u001b[0m\n",
      "from average_filter_plugin.operators_loader import load_operators\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m operators.py:\n",
      " \u001b[0m\n",
      "from ansys.dpf.core.custom_operator import CustomOperatorBase\n",
      "from ansys.dpf.core.operator_specification import CustomSpecification, PinSpecification, SpecificationProperties\n",
      "from ansys.dpf import core as dpf\n",
      "from average_filter_plugin import common\n",
      "\n",
      "\n",
      "class IdsWithDataHigherThanAverage(CustomOperatorBase):\n",
      "    def run(self):\n",
      "        field = self.get_input(0, dpf.Field)\n",
      "        average = common.compute_average_of_field(field)\n",
      "        ids_in = field.scoping.ids\n",
      "        data_in = field.data\n",
      "        out = []\n",
      "        for i, d in enumerate(data_in):\n",
      "            if d >= average:\n",
      "                out.append(ids_in[i])\n",
      "        scoping_out = dpf.Scoping(ids=out, location=field.scoping.location)\n",
      "        self.set_output(0, scoping_out)\n",
      "        self.set_succeeded()\n",
      "\n",
      "    @property\n",
      "    def specification(self):\n",
      "        spec = CustomSpecification(\"Creates a scoping with all the ids having data higher or equal \"\n",
      "                                   \"to the average value of the scalar field's data in input.\")\n",
      "        spec.inputs = {\n",
      "            0: PinSpecification(\"field\", type_names=dpf.Field, document=\"scalar Field.\"),\n",
      "        }\n",
      "        spec.outputs = {\n",
      "            0: PinSpecification(\"scoping\", type_names=dpf.Scoping),\n",
      "        }\n",
      "        spec.properties = SpecificationProperties(user_name=\"ids with data higher than average\", category=\"logic\")\n",
      "        return spec\n",
      "\n",
      "    @property\n",
      "    def name(self):\n",
      "        return \"ids_with_data_higher_than_average\"\n",
      "\n",
      "\n",
      "class IdsWithDataLowerThanAverage(CustomOperatorBase):\n",
      "    def run(self):\n",
      "        field = self.get_input(0, dpf.Field)\n",
      "        average = common.compute_average_of_field(field)\n",
      "        ids_in = field.scoping.ids\n",
      "        data_in = field.data\n",
      "        out = []\n",
      "        for i, d in enumerate(data_in):\n",
      "            if d <= average:\n",
      "                out.append(ids_in[i])\n",
      "        scoping_out = dpf.Scoping(ids=out, location=field.scoping.location)\n",
      "        self.set_output(0, scoping_out)\n",
      "        self.set_succeeded()\n",
      "\n",
      "    @property\n",
      "    def specification(self):\n",
      "        spec = CustomSpecification(\"Creates a scoping with all the ids having data lower or equal \"\n",
      "                                   \"to the average value of the scalar field's data in input.\")\n",
      "        spec.inputs = {\n",
      "            0: PinSpecification(\"field\", type_names=dpf.Field, document=\"scalar Field.\"),\n",
      "        }\n",
      "        spec.outputs = {\n",
      "            0: PinSpecification(\"scoping\", type_names=dpf.Scoping),\n",
      "        }\n",
      "        spec.properties = SpecificationProperties(user_name=\"ids with data lower than average\", category=\"logic\")\n",
      "        return spec\n",
      "\n",
      "    @property\n",
      "    def name(self):\n",
      "        return \"ids_with_data_lower_than_average\"\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m operators_loader.py:\n",
      " \u001b[0m\n",
      "from average_filter_plugin import operators\n",
      "from ansys.dpf.core.custom_operator import record_operator\n",
      "\n",
      "\n",
      "def load_operators(*args):\n",
      "    record_operator(operators.IdsWithDataHigherThanAverage, *args)\n",
      "    record_operator(operators.IdsWithDataLowerThanAverage, *args)\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m common.py:\n",
      " \u001b[0m\n",
      "import numpy\n",
      "\n",
      "\n",
      "def compute_average_of_field(field):\n",
      "    return numpy.average(field.data)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "import os\n",
    "print('\\033[1m average_filter_plugin')\n",
    "print('\\033[1m __init__.py:\\n \\033[0m')\n",
    "print(IPython.display.Code(os.path.join(os.getcwd(),\"../plugins/average_filter_plugin/__init__.py\")))\n",
    "print('\\n\\n\\033[1m operators.py:\\n \\033[0m')\n",
    "print(IPython.display.Code(os.path.join(os.getcwd(),\"../plugins/average_filter_plugin/operators.py\")))\n",
    "print('\\n\\n\\033[1m operators_loader.py:\\n \\033[0m')\n",
    "print(IPython.display.Code(os.path.join(os.getcwd(),\"../plugins/average_filter_plugin/operators_loader.py\")))\n",
    "print('\\n\\n\\033[1m common.py:\\n \\033[0m')\n",
    "print(IPython.display.Code(os.path.join(os.getcwd(),\"../plugins/average_filter_plugin/common.py\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Plugin\n",
    "Once a python plugin is written as a package, it can be loaded with the function\n",
    ":py:func:`ansys.dpf.core.core.load_library` taking as first argument the path to the directory of the plugin,\n",
    "as second argument ``py_`` + any name identifying the plugin,\n",
    "and as last argument the function's name exposed in the __init__ file and used to record operators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Established connection to DPF gRPC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'py_average_filter successfully loaded'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from ansys.dpf import core as dpf\n",
    "from ansys.dpf.core import examples\n",
    "\n",
    "tmp = dpf.make_tmp_dir_server()\n",
    "dpf.upload_files_in_folder(\n",
    "    dpf.path_utilities.join(tmp, \"average_filter_plugin\"),\n",
    "    os.path.join(os.getcwd(),\"../plugins\", \"average_filter_plugin\")\n",
    ")\n",
    "dpf.load_library(\n",
    "    os.path.join(dpf.path_utilities.join(tmp, \"average_filter_plugin\")),\n",
    "    \"py_average_filter\",\n",
    "    \"load_operators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Plugin loaded, Operators recorded in the plugin can be used with:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_operator = dpf.Operator(\"ids_with_data_lower_than_average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this new Operator, a workflow computing the norm of the displacement\n",
    "is connected to the \"ids_with_data_lower_than_average\" Operator.\n",
    "Methods of the class ``ids_with_data_lower_than_average`` are dynamically added thanks to the Operator's\n",
    "specification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Custom Operator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoping in was: DPF  Scoping: \n",
      "  with Nodal location and 81 entities\n",
      "\n",
      "----------------------------------------------\n",
      "scoping out is: DPF  Scoping: \n",
      "  with Nodal location and 35 entities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = dpf.DataSources(dpf.upload_file_in_tmp_folder(examples.static_rst))\n",
    "displacement = dpf.operators.result.displacement(data_sources=ds)\n",
    "norm = dpf.operators.math.norm(displacement)\n",
    "new_operator.inputs.connect(norm)\n",
    "\n",
    "\n",
    "new_scoping = new_operator.outputs.scoping()\n",
    "print(\"scoping in was:\", norm.outputs.field().scoping)\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"scoping out is:\", new_scoping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
