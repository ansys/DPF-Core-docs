{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Connect workflows on different processes implicitly\n",
    "This example shows how distributed files can be read and post processed\n",
    "on distributed processes. After remote post processing,\n",
    "results a merged on the local process. In this example, different workflows are\n",
    "directly created on different servers. Those workflows are then connected\n",
    "together without having to care that they are on remote processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dpf module and its examples files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from ansys.dpf import core as dpf\n",
    "from ansys.dpf.core import examples\n",
    "from ansys.dpf.core import operators as ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the servers\n",
    "Start three dpf servers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "server1 = dpf.start_local_server(as_global=False)\n",
    "server2 = dpf.start_local_server(as_global=False)\n",
    "server3 = dpf.start_local_server(as_global=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create template workflows on remote servers\n",
    "For the purpose of this example, we will create 2 workflows computing\n",
    "elemental nodal stresses on different servers. The second workflow will\n",
    "multiply by 2.0 the stresses. A last workflow will merge the outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "local_files = examples.download_distributed_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first workflow S\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "workflow1 = dpf.Workflow(server=server1)\n",
    "server_file_path1 = dpf.upload_file_in_tmp_folder(local_files[0], server=server1)\n",
    "model = dpf.Model(server_file_path1, server=server1)\n",
    "stress1 = model.results.stress()\n",
    "workflow1.add_operator(stress1)\n",
    "workflow1.set_output_name(\"out1\", stress1.outputs.fields_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second workflow S*2.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "workflow2 = dpf.Workflow(server=server2)\n",
    "server_file_path2 = dpf.upload_file_in_tmp_folder(local_files[1], server=server2)\n",
    "model = dpf.Model(server_file_path2, server=server2)\n",
    "stress2 = model.results.stress()\n",
    "mul = stress2 * 2.0\n",
    "workflow2.add_operator(mul)\n",
    "workflow2.set_output_name(\"out2\", mul.outputs.fields_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "third workflow merge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "workflow3 = dpf.Workflow(server=server3)\n",
    "merge = ops.utility.merge_fields_containers()\n",
    "nodal = ops.averaging.to_nodal_fc(merge)\n",
    "workflow3.add_operators([merge, nodal])\n",
    "workflow3.set_input_name(\"in1\", merge, 0)\n",
    "workflow3.set_input_name(\"in2\", merge, 1)\n",
    "workflow3.set_output_name(\"merged\", nodal.outputs.fields_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect the workflows together and get the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "workflow3.connect_with(workflow1, (\"out1\", \"in1\"))\n",
    "workflow3.connect_with(workflow2, (\"out2\", \"in2\"))\n",
    "\n",
    "fc = workflow3.get_output(\"merged\", dpf.types.fields_container)\n",
    "fc[0].meshed_region.plot(fc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
